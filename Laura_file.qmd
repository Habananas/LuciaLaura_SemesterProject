---
title: "Strava_File"
format: html
---

# STRAVA PROJECT 


____________ Abstract Lucia
As we tried to think of possible project ideas for our semester project,
the quality of our data and the accuracy of the given meta data
confronted us with major limitations. As this seems to be a common
problem for trajectory research (Sadeghian et al. 2020), we will try to
solve this hurdle on a computational basis. Methods applied include
segmentation, k-means clustering and similarity analysis.  
____________ end


### Libraries and Files
```{r}
# install.packages("XML")
# install.packages("gitcreds")
library("readr")
library(sf)
library(ggplot2)
library(dplyr)
library("gitcreds")
library(XML) #to read the XML data of gpx files
library(leaflet) #to show in a map

laura_act <- read.csv("data/activities_Laura.csv")
#lucia_act <- read.csv("NO FILE ")
```

### Understanding GPX 
https://www.appsilon.com/post/r-gpx-files
GPX is a very common map data format used to store GPS data of routes. GPX is basically XML, therefore, we need to install the XML package. 

- GPX is just a fancier version of xml, so we can recycle sml tools
We will load the data of one GPX track as a html file, but the loaded gpx data looks pretty messy, It is thus necessary to tidy it by identifying key structures: 
- trkpt element = contains latitude and longitude information for every point
- ele tag = contains the elevation.
- time = contains UTC-8 Timeinformation

The html looks like this: 
</trkpt><trkpt lat="47.2176510" lon="8.6811000"> <ele>511.9<
/ele><time>2024-03-25T16:03:41Z<
/time><extensions><trackpointextension><cad>0</cad></trackpointextension></extensions>


### Data Exploration and Organisation
```{r}

# Get a list of files in the folder
folder_path <- "data/activities_Laura/"
file_list <- list.files(folder_path, full.names = TRUE)

```

### Function
Create a function that assigns coordinates, elevation, time and activity name out of the gpx file, then apply this function to all of the gpx files:
```{r}
gpx_to_df <- function(gpx_path) {
  
  gpx_parsed <- htmlTreeParse(file = gpx_path, useInternalNodes = TRUE)
  
  # read out elements of the html file to vecotrs
coords <- xpathSApply(doc = gpx_parsed, path = "//trkpt", fun = xmlAttrs)
elevation <- xpathSApply(doc = gpx_parsed, path = "//trkpt/ele", fun = xmlValue)
time <- xpathSApply(doc = gpx_parsed, path = "//time", fun = xmlValue)
activity_name <- xpathSApply(doc = gpx_parsed, path = "//name", fun = xmlValue)
activity_type <- xpathSApply(doc = gpx_parsed, path = "//type", fun = xmlValue)

# remove first value of time, as it stems from the metadata and matches the second value (i.e. first timestamp of trackpoint)
time <- time[-1]

# convert vectors to a data frame
df <- data.frame(
  lat = as.numeric(coords["lat", ]),
  lon = as.numeric(coords["lon", ]),
  elevation = as.numeric(elevation), 
  timestamp = as.POSIXct(time,tz="UTC", format=c("%Y-%m-%dT%H:%M:%OS")),
  ActivityName = activity_name,
  ActivityType = activity_type
) 

dfname <- print(substring(gpx_path, 12, 34))

assign(dfname, df, envir = .GlobalEnv)
}

# Iterate over each file and apply your function
for (file_path in file_list) {
  gpx_to_df(file_path)
}

```

### Combine single track-files to one Dataframe
```{r}
#create a list of the df names
file_list
dflist_Laura <- substring(file_list,12,34)
dflist_Laura
all_tracks_Laura <- do.call(rbind, lapply(dflist_Laura, get))
```


### Converting the df to sf object
```{r}
library(sf)
all_tracks_Laura <- st_as_sf(all_tracks_Laura, coords = c("lon", "lat"), crs = 4326)
str(all_tracks_Laura)
```

### Transforming the crs & Timezone
We would like the CRS to be in the format of CH1903 +LV95 or EPSG:2056
```{r}
all_tracks_Laura <- st_transform(all_tracks_Laura, 2056)
str(all_tracks_Laura)

# Check Timezone
attr(all_tracks_Laura$timestamp, "tzone")
```



###  Filtering out old data
```{r}
library(lubridate)
all_tracks_Laura <- all_tracks_Laura |> 
  mutate("year" = year(timestamp)) |> 
  filter(year == 2024)
```

### (LAURA) Trajectories per day (so every activity that was done on a new day gets a new ID)
```{r}

all_tracks_Laura <- all_tracks_Laura %>%
  mutate(timestamp = ymd_hms(timestamp)) %>%
  arrange(timestamp) %>%
  mutate(diff = c(0, diff(timestamp)),
         trajID = cumsum(diff > hours(2)))%>%
  mutate(trajID = trajID + 1)

all_tracks_Laura$diff <- NULL
```

### Making a map of the data
```{r}
library(tmap)

tmap_mode("view")

#reclassify trackID as char:
class(all_tracks_Laura$trajID)
as.numeric(all_tracks_Laura$trajID)
all_tracks_Laura$trajID <- as.character(all_tracks_Laura$trajID)

# display all trajectories by trackID 
tm_shape(all_tracks_Laura)+
  tm_dots(col = "trajID", palette = "RdYlGn") 

```

### changing activity Type
```{r}

all_tracks_Laura <- all_tracks_Laura %>%
  mutate(ActivityType = ifelse(trajID == 2, "car", ActivityType))

all_tracks_Laura <- all_tracks_Laura %>%
  mutate(ActivityType = ifelse(trajID == 3, "mixed", ActivityType))


all_tracks_Laura <- all_tracks_Laura %>%
  mutate(ActivityType = ifelse(trajID == 1, "trainride", ActivityType))

all_tracks_Laura <- all_tracks_Laura %>%
  mutate(ActivityType = ifelse(ActivityType == "Canoeing", "trainride", ActivityType))
```

### filter by activity Type & create new DFs with it

```{r}
 running_Laura <- all_tracks_Laura  |> 
  filter(ActivityType == "running")

bike_Laura <- all_tracks_Laura  |> 
  filter(ActivityType == "cycling")

train <- all_tracks_Laura  |> 
  filter(ActivityType == "trainride")

car_Laura <- all_tracks_Laura  |> 
  filter(trajID == "2") #this one I saw from the movement pattern , or ActivityType == "car"

mixed_Laura <- all_tracks_Laura |> 
  filter(ActivityType=="mixed")
```
### display activities by type
```{r}

tm_shape(all_tracks_Laura)+
  tm_dots(col = "ActivityType", palette = "Paired") 
```
Here, we can see the 5 different categories, of which one is "mixed", meaning walking, running, tram. 
This one might be interesting to analyze with unsupervised learning algorithm k means. Then we can see if it works for the others as well.  
Therefore, we need to segment by stops, then define the cluster conditions and then cluster the segments accordingly. 

## Segmentation by speed 
Use Function distance_by_element in combination with lead() and lag() to calculate euclidian distance 
We cannot use segmentation by static, bc the mean(stepMean) is too high for the stepMean when the person is walking. So, we want to segment by speed change. When the step mean is <20 (meaning 1m/1s=3,6km/h), the category is walking 
when the Step Mean is 20-40  it is running, and everything >40 is tram.  --- wrong thought! We first calculate the speed between two points. 
```{r}
 distance_by_element <- function(later, now) {
  as.numeric(
    st_distance(later, now, by_element = TRUE)
  )
 }

#install.packages("slider")
library(slider)
mixed_Laura<- mixed_Laura |>
    mutate(
        distance  = distance_by_element(geometry, lead(geometry, 1)), # distance to pos +1 
       time_diff = c(NA, difftime(timestamp[-1], timestamp[-length(timestamp)], units = "secs")),
       speed= distance/time_diff,
       speed_kmh = round(speed*3.6),
       acceleration = (speed - lag(speed)) / time_diff,
       avg_acc_10s = slide_dbl(acceleration, sum, .before = 5, .after = 5, .complete = TRUE) / 
                       slide_dbl(time_diff, sum, .before = 5, .after = 5, .complete = TRUE) #aus dem package slider, berechnet die gleitende Summe der Beschleunigungswerte über 10 Punkte
    )


tm_shape(mixed_Laura)+
  tm_dots(col = "speed", palette = "RdYlGn") 

```

```{r}

# We want a time window of 20 seconds. As we have a point every second, we want to 
mixed_Laura<- mixed_Laura |>
    mutate(
        nMinus2 = distance_by_element(lag(geometry, 10), geometry),  # distance to pos -10 sec
        nMinus1 = distance_by_element(lag(geometry, 5), geometry),  # distance to pos -5 sec
        nPlus1  = distance_by_element(geometry, lead(geometry, 5)), # distance to pos +5 sec
        nPlus2  = distance_by_element(geometry, lead(geometry, 10))  # distance to pos +10 sec 
    )


#but this just calculates the distance by element, not by seconds! In case there was a measurement left out, we do not obtain the correct velocity data, which is the case e.g. in tunnels. Therefore we would need sth like this: (talk to lucia)
#nMinus2 = distance_by_element(lag(geometry, 10), geometry)/difftime(lag(geometry,10)),


# calculate Meanstep
mixed_Laura<- mixed_Laura |>
    rowwise() |>
    mutate(
        stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))
    ) |>
    ungroup()

tm_shape(mixed_Laura)+
  tm_dots(col = "stepMean", palette = "RdYlGn") 


#we can see that the step mean varies a lot. 


#here, we define the categories according to the step mean 
mixed_Laura  <- mixed_Laura  |>
  mutate(category = case_when(
    stepMean < 20 ~ "walking",
    stepMean >= 20 & stepMean < 40 ~ "running", 
    stepMean >= 40 ~ "tram"
  ))

# somehow this doesnt work??

mixed_Laura  <- mixed_Laura  |>
  mutate(category = case_when(
    speed_kmh < 3.5 ~ "walking",
    speed_kmh >= 3.5 & stepMean < 18 ~ "running", 
    speed_kmh >= 18 ~ "tram"
  ))

tm_shape(mixed_Laura)+
  tm_dots(col = "category", palette = "RdYlGn") 


#if we want to exclude the static movements, which in this case leads to the exclusion of half of the trajectory!!! thats actually not waht we want
#mixed_Laura <- mixed_Laura |>
    #mutate(static = stepMean < mean(stepMean, na.rm = TRUE))
#summary(mixed_Laura)

#mixed_Laura_filter <- mixed_Laura |>
    filter(!static)

#tm_shape(mixed_Laura_filter)+
  #tm_dots(col = "stepMean", palette = "RdYlGn") 


```

### Join with spatial data
```{r}

lines <- read_csv("taz.komm_richt_verkehr_l.csv")
lines <- st_as_sf(lines,  wkt="geometry")
lines <- st_set_crs(lines, 2056)


lines_select <- lines %>%
  select(objectid, kategorie, teilplan, geometry)

plot(lines_select)

tm_shape(lines_select)+
  tm_lines(col="kategorie") +
tm_shape(mixed_Laura)+
  tm_dots(col="speed_kmh")

#jetzt verbinden wir die beiden Tables, allerdings nicht mit st_intersect, weil es keine gibt, sondern neighbourhood analysis: 

joined <- st_join(mixed_Laura, lines_select, 
                  join = st_is_within_distance, 
                       dist = 2, # Distanz in Metern
                       left = TRUE)# damit auch werte erhalten bleiben, die nicht within distance sind

# das Anreichern mit Kategorien wird aber später bei k means ein problem, weil er drop NA macht...

tm_shape(lines_select)+
  tm_lines(col="kategorie") +
tm_shape(joined)+
  tm_dots(col="speed_kmh")


```

## erster versuch K means
```{r}
mixed_select <- joined %>%
  select(distance,speed_kmh, avg_acc_10s, kategorie)

#install.packages("factoextra")
#install.packages("cluster")
library(factoextra)
library(cluster)

mixed_select <- na.omit(mixed_select) #otherwise fehlermeldung
mixed_select <- st_drop_geometry(mixed_select) # necessary so geometry column goes away, otherwise fviz not work

# to find the good amount of k 
fviz_nbclust(mixed_select, kmeans, method = "wss")

km <- kmeans(unlist(mixed_select), centers = 4, nstart = 25)

km #hä was ist das?
```



## calculate sinuosity
```{r}
install.packages("trajr")
library(trajr)

coords <- st_coordinates(mixed_Laura)

# Add x and y columns to the sf object
mixed_Laura$x <- coords[,1]
mixed_Laura$y <- coords[,2]

# doesnt work. 

trj <- TrajsBuild(data = "mixed_Laura", x = "x", y = "y", time = "timestamp", geometry = "geometry")

sinuosity <- TrajSinuosity2(trj)

```


# Old Stuff (not to use)

```{r}
#the coord info is in gpx file for every activity. 
coords <- xpathSApply(doc = gpx_1, path = "//trkpt", fun = xmlAttrs) # question: if we use the same from gpx1 for all, is that a problem?
elevation <- xpathSApply(doc = gpx_1, path = "//trkpt/ele", fun = xmlValue) # same question

df <- data.frame(
  lat = as.numeric(coords["lat", ]),
  lon = as.numeric(coords["lon", ]),
  elevation = as.numeric(elevation)
)

head(df, 10)
tail(df, 10)

plot(x = df$lon, y = df$lat, type = "l", col = "black", lwd = 3,
     xlab = "Longitude", ylab = "Latitude")
```
###CHAT GTP idea: 
make a df that has all the lat lon and elevation infos of all the trips, and give them a column with a unique ID per trip. 
then this huge df can be set into one map, structured by ID. 
therefore, I would need to add a column that has the ID 
```{r}
#CHAT GTP proposes this: 
gpx_files <- list.files("data/Laura_Strava/activities", pattern = "\\.gpx$", full.names = TRUE)

head(gpx_files)

process_gpx <- function(file, id) {
  doc <- xmlTreeParse(file, useInternalNodes = TRUE)
  coords <- xpathApply(doc, "//trkpt", function(x) as.numeric(xmlAttrs(x)[c("lat", "lon")]))
  elevation <- xpathSApply(doc, "//trkpt/ele", xmlValue)
  df <- data.frame(
    lat = coords[, 1],
    lon = coords[, 2],
    elevation = as.numeric(elevation),
    object_id = id
  )
  return(df)
}

all_data <- do.call(rbind, lapply(seq_along(gpx_files), function(i) {
  process_gpx(gpx_files[i], i)
}))

head(all_data)

```


```{r}
library(XML)

# Create a list of all GPX file paths
gpx_files <- list.files("data/Laura_Strava/activities", pattern = "\\.gpx$", full.names = TRUE)

# Function to process a single GPX file
process_gpx <- function(file, id) {
  doc <- xmlTreeParse(file, useInternalNodes = TRUE)
  
  coords <- xpathApply(doc, "//trkpt", function(node) {
    lat <- as.numeric(xmlValue(node["lat"]))
    lon <- as.numeric(xmlValue(node["lon"]))
    return(c(lat, lon))
  })
  
  elevation <- xpathSApply(doc, "//trkpt/ele", xmlValue)
  
  df <- data.frame(
    id = id,
    lat = unlist(coords[1,]),
    lon = unlist(coords[2,]),
    elevation = as.numeric(elevation)
  )
  
  return(df)
}

# Process all GPX files and combine into a single dataframe
all_data <- do.call(rbind, lapply(seq_along(gpx_files), function(i) {
  process_gpx(gpx_files[i], i)
}))

```


### loading several files into one Map
https://stackoverflow.com/questions/54726758/merging-multiple-gpx-files-into-a-single-gpx-file-with-multiple-tracks --- didnt work, as old plotKML used and bc of other stuff. 

```{r}
gpx_files <- c("data/Laura_Strava/activities/11091356418.gpx","data/Laura_Strava/activities/11103101530.gpx", "data/Laura_Strava/activities/11116616348.gpx", "data/Laura_Strava/activities/11188517987.gpx", "data/Laura_Strava/activities/11203431760.gpx", "data/Laura_Strava/activities/11209427592.gpx", "data/Laura_Strava/activities/11239313364.gpx")


```

```{r}
```




## colouring etc
```{r}
library(leaflet)

leaflet() %>%
  addTiles() %>%
  addPolylines(data = df, lat = ~lat, lng = ~lon, color = "#000000", opacity = 0.8, weight = 3)


get_color <- function(elevation) {
  if (elevation < 500) {
    return("green")
  }
  if (elevation < 1000) {
    return("yellow")
  }
  if (elevation < 1500) {
    return("orange")
  }
  return("red")
}




# New dataset with the new variable for color
df_color <- df %>%
  rowwise() %>%
  mutate(color = get_color(elevation))

df_color$last_color <- dplyr::lag(df_color$color)

# Map
map <- leaflet() %>% addTiles()
for (color in levels(as.factor(df_color$color))) {
  map <- addPolylines(map, lat = ~lat, lng = ~lon, data = df_color[df_color$color == color | df_color$last_color == color, ], color = ~color)
}
map
```
